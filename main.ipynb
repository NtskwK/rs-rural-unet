{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms import v2\n",
    "\n",
    "from unet.dataloader import LoveDA\n",
    "from unet.loss import DiceFocalLoss\n",
    "from unet.net import UNet\n",
    "from unet.train import validate_model"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "lr = 1e-4\n",
    "batch_size = 32\n",
    "num_epochs = 20"
   ],
   "id": "a2a872cdcffe954d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "print(\"Initializing datasets...\")\n",
    "# 创建数据集对象\n",
    "train_transform = v2.Compose(\n",
    "    [\n",
    "        v2.RandomResizedCrop((256, 256), scale=(0.8, 1.2), ratio=(0.75, 1.33)),\n",
    "        v2.RandomRotation(degrees=(-180.0, 180.0)),\n",
    "        v2.RandomHorizontalFlip(p=0.5),\n",
    "        v2.RandomVerticalFlip(p=0.5),\n",
    "        v2.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
    "        v2.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ]\n",
    ")\n",
    "val_transform = v2.Compose(\n",
    "    [\n",
    "        v2.Resize((256, 256), antialias=True),\n",
    "        v2.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ]\n",
    ")\n",
    "train_rural_dataset = LoveDA(\n",
    "    Path(\"dataset/Train/Rural/images_png_resized\"),\n",
    "    Path(\"dataset/Train/Rural/masks_png_resized\"),\n",
    "    transform=train_transform,\n",
    ")\n",
    "train_urban_dataset = LoveDA(\n",
    "    Path(\"dataset/Train/Urban/images_png_resized\"),\n",
    "    Path(\"dataset/Train/Urban/masks_png_resized\"),\n",
    "    transform=train_transform,\n",
    ")\n",
    "train_dataset = torch.utils.data.ConcatDataset(\n",
    "    [train_rural_dataset, train_urban_dataset]\n",
    ")\n",
    "val_rural_dataset = LoveDA(\n",
    "    Path(\"dataset/Val/Rural/images_png_resized\"),\n",
    "    Path(\"dataset/Val/Rural/masks_png_resized\"),\n",
    "    transform=val_transform,\n",
    ")\n",
    "val_urban_dataset = LoveDA(\n",
    "    Path(\"dataset/Val/Urban/images_png_resized\"),\n",
    "    Path(\"dataset/Val/Urban/masks_png_resized\"),\n",
    "    transform=val_transform,\n",
    ")\n",
    "val_dataset = torch.utils.data.ConcatDataset([val_rural_dataset, val_urban_dataset])"
   ],
   "id": "38c4299bb14b64bb"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# 使用DataLoader包装数据集，并设置batch_size和num_workers\n",
    "print(\"Initializing dataloaders...\")\n",
    "train_dataloader = DataLoader(\n",
    "    train_dataset, batch_size=batch_size, num_workers=4, shuffle=True\n",
    ")\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=batch_size, num_workers=4)"
   ],
   "id": "4d1b9f6f737f6f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "print(\"Initializing model...\")\n",
    "if torch.cuda.is_available():\n",
    "    print(\"Using GPU...\")\n",
    "    device = torch.device(\"cuda\")\n",
    "    if torch.backends.cudnn.is_available():\n",
    "        print(\"Using cuDNN...\")\n",
    "        torch.backends.cudnn.benchmark = True\n",
    "else:\n",
    "    print(\"Using CPU...\")\n",
    "    device = torch.device(\"cpu\")"
   ],
   "id": "e2d7a9b13c56dff8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def denormalize(tensor, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]):\n",
    "    \"\"\"\n",
    "    反归一化图像张量以用于显示\n",
    "    \"\"\"\n",
    "    tensor = tensor.clone()\n",
    "    for t, m, s in zip(tensor, mean, std):\n",
    "        t.mul_(s).add_(m)\n",
    "    return tensor\n",
    "\n",
    "\n",
    "def visualize_prediction(model, dataset, device, epoch):\n",
    "    \"\"\"\n",
    "    随机选择一个验证样本进行预测并可视化\n",
    "    \"\"\"\n",
    "    # 随机选择一个样本\n",
    "    idx = random.randint(0, len(dataset) - 1)\n",
    "    image, mask = dataset[idx]\n",
    "\n",
    "    # 添加批次维度并移动到设备\n",
    "    image_tensor = image.unsqueeze(0).to(device)\n",
    "\n",
    "    # 获取模型预测\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        output = model(image_tensor)\n",
    "        # 对于多分类问题，使用argmax获取预测类别\n",
    "        prediction = torch.argmax(output, dim=1).cpu().numpy()[0]\n",
    "    model.train()\n",
    "\n",
    "    # 反归一化图像以用于显示\n",
    "    image_display = denormalize(image).permute(1, 2, 0).numpy()\n",
    "\n",
    "    # 创建可视化\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "    # 显示原图\n",
    "    axes[0].imshow(np.clip(image_display, 0, 1))\n",
    "    axes[0].set_title(f\"Original Image (Epoch {epoch})\")\n",
    "    axes[0].axis('off')\n",
    "\n",
    "    # 显示真实标签\n",
    "    axes[1].imshow(mask.numpy(), cmap='tab10')\n",
    "    axes[1].set_title(f\"Ground Truth\")\n",
    "    axes[1].axis('off')\n",
    "\n",
    "    # 显示预测结果\n",
    "    axes[2].imshow(prediction, cmap='tab10')\n",
    "    axes[2].set_title(f\"Prediction\")\n",
    "    axes[2].axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ],
   "id": "visualization_functions"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "model = UNet(3, 8).to(device)\n",
    "\n",
    "print(\"Initializing loss...\")\n",
    "# value\n",
    "# 无效       0\n",
    "# 背景\t    1\n",
    "# 建筑物\t    2\n",
    "# 道路\t    3\n",
    "# 水体\t    4\n",
    "# 荒地\t    5\n",
    "# 森林\t    6\n",
    "# 农业用地\t7\n",
    "\n",
    "# 创建忽略索引0的损失函数，num_classes设为8（包括0）\n",
    "loss = DiceFocalLoss(num_classes=8, ignore_index=0).to(device)\n",
    "\n",
    "print(\"Initializing optimizer...\")\n",
    "optimizer = optim.AdamW(model.parameters(), lr=lr, weight_decay=1e-3)\n",
    "\n",
    "print(\"Training...\")\n",
    "model.train()\n",
    "model.to(device)\n",
    "# 更改学习率调度器为更敏感的参数\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer, \"min\", patience=2, factor=0.5, min_lr=1e-7\n",
    ")\n",
    "\n",
    "# 添加早停机制\n",
    "best_val_loss = float('inf')\n",
    "patience_counter = 0\n",
    "patience_limit = 5\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for batch_idx, (data, target) in enumerate(train_dataloader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        # 计算损失\n",
    "        loss_value = loss(output, target)\n",
    "        loss_value.backward()\n",
    "        # 梯度裁剪\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch_idx % 10 == 0:\n",
    "            print(\n",
    "                f\"Epoch: {epoch}, Batch: {batch_idx}, Training Loss: {loss_value.item():.4f}\"\n",
    "            )\n",
    "\n",
    "    val_loss = validate_model(model, val_dataloader, loss, device)\n",
    "\n",
    "    # 更新学习率\n",
    "    scheduler.step(val_loss)\n",
    "    current_lr = optimizer.param_groups[0][\"lr\"]\n",
    "\n",
    "    print(f\"Epoch: {epoch}, Validation Loss: {val_loss:.4f}, LR: {current_lr:.6f}\")\n",
    "\n",
    "    # 随机选择一个验证样本进行预测并可视化\n",
    "    visualize_prediction(model, val_dataset, device, epoch)\n",
    "\n",
    "    # 早停机制\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        patience_counter = 0\n",
    "        # 保存最佳模型\n",
    "        torch.save(model.state_dict(), 'best_model.pth')\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "\n",
    "    if patience_counter >= patience_limit:\n",
    "        print(f\"Early stopping at epoch {epoch}\")\n",
    "        break"
   ],
   "id": "94c0c18db1a9ad09"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
